# å¿«é€Ÿå¼€å§‹æŒ‡å—

5 åˆ†é’Ÿä¸Šæ‰‹ MHC Forward Pre ç®—å­ã€‚

---

## 1. å®‰è£…

```bash
# å…‹éš†ä»“åº“
git clone https://github.com/folrent1896/mhc_ops.git
cd mhc_ops

# å®‰è£…ä¾èµ–
pip install torch triton

# å¼€å‘æ¨¡å¼å®‰è£…
pip install -e .
```

---

## 2. å¿«é€Ÿæµ‹è¯•

```bash
# Forward å¿«é€Ÿæµ‹è¯•
python test/forward/quick_test.py

# æ€§èƒ½åŸºå‡†æµ‹è¯•
python test/forward/benchmark.py
```

**é¢„æœŸè¾“å‡ºï¼š**
```
âœ“ Configuration: B=2, S=256, n=4, D=256
âœ“ PyTorch Reference: 8.23 ms
âœ“ Triton: 3.46 ms
âœ“ Speedup: 2.38x
âœ“ Status: PASS
```

---

## 3. åŸºç¡€ä½¿ç”¨

### 3.1 Forwardï¼ˆå‰å‘ä¼ æ’­ï¼‰

```python
from src.forward import mhc_forward_pre
import torch

# å‡†å¤‡è¾“å…¥
B, S, n, D = 2, 128, 4, 256
x = torch.randn(B, S, n, D, dtype=torch.bfloat16)
phi = torch.randn(n*n + 2*n, n*D, dtype=torch.float32)
alpha = torch.tensor([1.1, 0.9, 1.05], dtype=torch.float32)
bias = torch.randn(n*n + 2*n, dtype=torch.float32) * 0.1

# æ‰§è¡Œ
h_in, h_post, h_res = mhc_forward_pre(x, phi, alpha, bias)

print(f"è¾“å‡ºå½¢çŠ¶:")
print(f"  h_in:   {h_in.shape}")     # [2, 128, 256]
print(f"  h_post: {h_post.shape}")   # [2, 128, 4]
print(f"  h_res:  {h_res.shape}")    # [2, 128, 4, 4]
```

### 3.2 GPU åŠ é€Ÿç‰ˆæœ¬

```python
from src.forward.mhc_forward_pre_triton import mhc_forward_pre_triton_optimized
import torch

device = 'cuda' if torch.cuda.is_available() else 'cpu'

# åœ¨ GPU ä¸Šè¿è¡Œ
x = torch.randn(B, S, n, D, dtype=torch.bfloat16, device=device)
phi = torch.randn(n*n + 2*n, n*D, dtype=torch.float32, device=device)
alpha = torch.tensor([1.1, 0.9, 1.05], device=device)
bias = torch.randn(n*n + 2*n, dtype=torch.float32, device=device) * 0.1

# GPU åŠ é€Ÿçš„å‰å‘ä¼ æ’­
h_in, h_post, h_res = mhc_forward_pre_triton_optimized(x, phi, alpha, bias)
```

### 3.3 Backwardï¼ˆåå‘ä¼ æ’­ï¼‰

```python
from src.forward import mhc_forward_pre
from src.backward import mhc_backward_manual
import torch

# å‰å‘ä¼ æ’­ï¼ˆéœ€è¦ä¸­é—´å€¼ï¼‰
h_in, h_post, h_res, inv_rms, h_mix, h_pre = mhc_forward_pre(
    x, phi, alpha, bias, outflag=True
)

# å‡†å¤‡æ¢¯åº¦
dh_in = torch.ones_like(h_in)
dh_post = torch.ones_like(h_post)
dh_res = torch.ones_like(h_res)
gamma = torch.randn(n, D)

# åå‘ä¼ æ’­
dx, dphi, dalpha, dbias, dgamma = mhc_backward_manual(
    x, phi, alpha, bias,
    inv_rms, h_mix, h_pre, h_post,
    dh_in, dh_post, dh_res, gamma
)
```

### 3.4 ä½¿ç”¨ Triton Backwardï¼ˆGPU åŠ é€Ÿï¼‰

```python
from src.forward import mhc_forward_pre
from src.backward.mhc_backward_triton import mhc_backward_triton
import torch

# åœ¨ GPU ä¸Šè¿è¡Œ
device = 'cuda'

# å‡†å¤‡è¾“å…¥ï¼ˆç§»åˆ° GPUï¼‰
x = torch.randn(B, S, n, D, dtype=torch.bfloat16, device=device)
phi = torch.randn(n*n + 2*n, n*D, dtype=torch.float32, device=device)
alpha = torch.tensor([1.1, 0.9, 1.05], device=device)
bias = torch.randn(n*n + 2*n, dtype=torch.float32, device=device) * 0.1

# å‰å‘ä¼ æ’­ï¼ˆéœ€è¦ä¸­é—´å€¼ï¼‰
h_in, h_post, h_res, inv_rms, h_mix, h_pre = mhc_forward_pre(
    x, phi, alpha, bias, outflag=True
)

# å‡†å¤‡æ¢¯åº¦
dh_in = torch.ones_like(h_in)
dh_post = torch.ones_like(h_post)
dh_res = torch.ones_like(h_res)
gamma = torch.randn(n, D, device=device)

# åå‘ä¼ æ’­ï¼ˆTriton åŠ é€Ÿï¼‰
dx, dphi, dalpha, dbias, dgamma = mhc_backward_triton(
    x, phi, alpha, bias,
    inv_rms, h_mix, h_pre, h_post,
    dh_in, dh_post, dh_res, gamma
)
```

**Triton Backward çŠ¶æ€** (2025-02-25):
- âœ… **æ‰€æœ‰ç»„ä»¶å®Œå…¨æ­£ç¡®å¹¶é€šè¿‡éªŒè¯ï¼**
- âœ… dphi, dalpha, dbias, dgamma: max_err < 1e-4
- âœ… dx: max_err = 0.25 (bfloat16 ç²¾åº¦é™åˆ¶ï¼Œå¯æ¥å—)
- âœ… å¯ç”¨äºç”Ÿäº§ç¯å¢ƒï¼

---

## 4. å®é™…åœºæ™¯ç¤ºä¾‹

### 4.1 é›†æˆåˆ°æ¨¡å‹

```python
import torch
import torch.nn as nn
from src.forward.mhc_forward_pre_triton import mhc_forward_pre_triton_optimized

class MHCBlock(nn.Module):
    """MHC æ¨¡å—"""
    def __init__(self, n=4, D=256):
        super().__init__()
        self.n = n
        self.D = D
        self.out_features = n * n + 2 * n

        # å¯å­¦ä¹ å‚æ•°
        self.phi = nn.Parameter(torch.randn(self.out_features, n * D))
        self.alpha = nn.Parameter(torch.tensor([1.1, 0.9, 1.05]))
        self.bias = nn.Parameter(torch.randn(self.out_features) * 0.1)

    def forward(self, x):
        """
        Args:
            x: [B, S, n, D]
        Returns:
            h_in, h_post, h_res
        """
        return mhc_forward_pre_triton_optimized(x, self.phi, self.alpha, self.bias)

# ä½¿ç”¨
model = MHCBlock(n=4, D=256).cuda()
x = torch.randn(2, 128, 4, 256, dtype=torch.bfloat16, device='cuda')
h_in, h_post, h_res = model(x)
```

### 4.2 è®­ç»ƒå¾ªç¯ç¤ºä¾‹

```python
import torch.nn as nn
import torch.optim as optim
from src.forward import mhc_forward_pre
from src.backward import mhc_backward_manual

# å‰å‘ä¼ æ’­
def forward_pass(x, phi, alpha, bias):
    return mhc_forward_pre(x, phi, alpha, bias, outflag=True)

# åå‘ä¼ æ’­
def backward_pass(x, phi, alpha, bias, outputs, grad_outputs, gamma):
    h_in, h_post, h_res, inv_rms, h_mix, h_pre = outputs
    dh_in, dh_post, dh_res = grad_outputs
    return mhc_backward_manual(
        x, phi, alpha, bias,
        inv_rms, h_mix, h_pre, h_post,
        dh_in, dh_post, dh_res, gamma
    )

# æ¨¡æ‹Ÿè®­ç»ƒå¾ªç¯
phi = torch.randn(24, 1024, requires_grad=True)
alpha = torch.tensor([1.1, 0.9, 1.05], requires_grad=True)
bias = torch.randn(24, requires_grad=True)
gamma = torch.randn(4, 256)

x = torch.randn(2, 128, 4, 256, dtype=torch.bfloat16)

# Forward
outputs = forward_pass(x, phi, alpha, bias)

# è®¡ç®—æŸå¤±
loss = outputs[0].sum() + outputs[1].sum() + outputs[2].sum()

# Backward
grad_outputs = (torch.ones_like(outputs[0]),
                 torch.ones_like(outputs[1]),
                 torch.ones_like(outputs[2]))
dx, dphi, dalpha, dbias, dgamma = backward_pass(
    x, phi, alpha, bias, outputs, grad_outputs, gamma
)

print(f"æ¢¯åº¦å½¢çŠ¶:")
print(f"  dx:     {dx.shape}")      # [2, 128, 4, 256]
print(f"  dphi:   {dphi.shape}")    # [24, 1024]
print(f"  dalpha: {dalpha.shape}")  # [3]
print(f"  dbias:  {dbias.shape}")   # [24]
print(f"  dgamma: {dgamma.shape}") # [4, 256]
```

---

## 5. å¸¸è§ä½¿ç”¨åœºæ™¯

### åœºæ™¯ 1: æ¨ç† (Inference)

```python
from src.forward.mhc_forward_pre_triton import mhc_forward_pre_triton_optimized

# æ¨ç†æ¨¡å¼
with torch.no_grad():
    h_in, h_post, h_res = mhc_forward_pre_triton_optimized(
        x, phi, alpha, bias
    )
```

### åœºæ™¯ 2: CPU ç¯å¢ƒ

```python
from src.forward import mhc_forward_pre

# CPU ä¸Šä½¿ç”¨ Golden å®ç°
h_in, h_post, h_res = mhc_forward_pre(x, phi, alpha, bias)
```

### åœºæ™¯ 3: è·å–ä¸­é—´å€¼

```python
from src.forward import mhc_forward_pre

# è®¾ç½® outflag=True è·å–ä¸­é—´å€¼ï¼ˆç”¨äº backwardï¼‰
h_in, h_post, h_res, inv_rms, h_mix, h_pre = mhc_forward_pre(
    x, phi, alpha, bias, outflag=True
)
```

---

## 6. æ€§èƒ½ä¼˜åŒ–å»ºè®®

### å°æ‰¹æ¬¡ (BÃ—S < 512)

```python
from src.forward.mhc_forward_pre_triton import mhc_forward_pre_triton

# ä½¿ç”¨å• kernel ç‰ˆæœ¬ï¼Œå¯åŠ¨å¼€é”€å°
h_in, h_post, h_res = mhc_forward_pre_triton(x, phi, alpha, bias)
```

### å¤§æ‰¹æ¬¡ (BÃ—S > 2048)

```python
from src.forward.mhc_forward_pre_triton import mhc_forward_pre_triton_optimized

# ä½¿ç”¨ä¼˜åŒ–ç‰ˆæœ¬ï¼Œååé‡æ›´é«˜
h_in, h_post, h_res = mhc_forward_pre_triton_optimized(x, phi, alpha, bias)
```

### è·¨å¹³å°éƒ¨ç½²

```python
from src.forward import MHCForwardPreTileLang

# ä½¿ç”¨ TileLangï¼Œå¯ç§»æ¤æ€§å¼º
op = MHCForwardPreTileLang(B, S, n, D)
h_in, h_post, h_res = op(x, phi, alpha, bias)
```

---

## 7. æ•…éšœæ’æŸ¥

### Q: Triton å¯¼å…¥å¤±è´¥ï¼Ÿ

```bash
pip install triton
```

### Q: CUDA å†…å­˜ä¸è¶³ï¼Ÿ

```python
# å‡å°æ‰¹æ¬¡å¤§å°
B, S, n, D = 1, 512, 4, 128
```

### Q: æµ‹è¯•å¤±è´¥ï¼Ÿ

```bash
# æ£€æŸ¥ç¯å¢ƒ
python -c "import torch; print(torch.cuda.is_available())"

# é‡æ–°è¿è¡Œæµ‹è¯•
python test/forward/quick_test.py
```

### Q: æ¢¯åº¦ä¸æ­£ç¡®ï¼Ÿ

```bash
# è¿è¡ŒéªŒè¯æµ‹è¯•
python test/backward/test_backward.py
```

---

## 8. ä¸‹ä¸€æ­¥

- ğŸ“– é˜…è¯»å®Œæ•´ [README.md](README.md)
- ğŸ“– æŸ¥çœ‹ [BACKWARD.md](BACKWARD.md) äº†è§£åå‘ä¼ æ’­
- ğŸ“– æŸ¥çœ‹ [PROJECT_STRUCTURE.md](PROJECT_STRUCTURE.md) äº†è§£é¡¹ç›®ç»“æ„
- ğŸ› æäº¤ [Issue](https://github.com/folrent1896/mhc_ops/issues) åé¦ˆé—®é¢˜

---

**å‡†å¤‡å¥½äº†å—ï¼Ÿå¼€å§‹ä½¿ç”¨å§ï¼**

```bash
# å¿«é€ŸéªŒè¯
python test/forward/quick_test.py

# æŸ¥çœ‹æ›´å¤šç¤ºä¾‹
cat README.md
```
